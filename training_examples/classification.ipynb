{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5aefb89-22aa-431e-b532-c636f07a50bf",
   "metadata": {},
   "source": [
    "## <center>How to adapt a pre-trained model to do sentiment classification <br> using SpaRTA</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372cecf9-9772-43a6-8f34-7f6d71ec9d2e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97069a7b-99a3-4ebd-873b-99d3d525a789",
   "metadata": {},
   "source": [
    "Specify your pre-trained model and output directory (for saving the adapter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f10d88-9410-43da-9c16-254c4a66f140",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa0e6c1-c42d-47d4-9120-15702a1ca32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-trained base model \n",
    "model_id = 'google/gemma-2b' \n",
    "\n",
    "# dir path for saving SpaRTA adapter\n",
    "home_dir = os.environ['HOME']\n",
    "save_dir = os.path.join(home_dir, 'sparta_examples/output/classification_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c5894-d545-4a80-b369-46971d1fe437",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9bc086-503a-4c1c-bcf0-1a64b01a4ab9",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799a42f9-ac14-4f9d-ae97-ecd87be28d1c",
   "metadata": {},
   "source": [
    "We load the SST-2 dataset from the GLUE benchmark. This dataset consists of movie reviews labeled as positive or negative. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b472eba2-728e-456a-9afd-dc4083614df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ebe0086-0905-4a7c-b634-7a754db67061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load task (classification) dataset\n",
    "dataset = load_dataset('glue', 'sst2')\n",
    "dataset = dataset.remove_columns('idx')\n",
    "dataset = dataset.rename_column('label', 'labels')\n",
    "del dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b24afe4-6db1-44fc-81fc-eb2bcec28700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'labels'],\n",
       "        num_rows: 67349\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence', 'labels'],\n",
       "        num_rows: 872\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded486b-39ab-425b-b264-8cbaeb15a267",
   "metadata": {},
   "source": [
    "We fix some spacing issues in the data by removing \"broken\" spaces inserted around punctuation or within contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea1f209-151a-4fde-bb55-c576340e4992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contains no wit , only labored gags ',\n",
       " \"a depressed fifteen-year-old 's suicidal poetry \",\n",
       " \"for those moviegoers who complain that ` they do n't make movies like they used to anymore \",\n",
       " \"swimming is above all about a young woman 's face , and by casting an actress whose face projects that woman 's doubts and yearnings , it succeeds . \"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1,8,11,19]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e252dd30-958c-4763-8a26-6df66f99d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "bad_spaces = re.compile(r\" ([.,)!:;%]|'(?:s|t|re|ve|m|ll|d) |n't )|(\\() |(s) (' )|( \\$) (\\d)\")\n",
    "    \n",
    "def repair_spaces(example):\n",
    "    example['sentence'] = bad_spaces.sub(r\"\\1\\2\\3\\4\\5\\6\", example['sentence']).strip()\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "488bbc06-b7c1-4624-851c-ea43b46fae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.map(repair_spaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a36be7a8-d32a-4cca-9324-95f42b19e2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contains no wit, only labored gags',\n",
       " \"a depressed fifteen-year-old's suicidal poetry\",\n",
       " \"for those moviegoers who complain that ` they don't make movies like they used to anymore\",\n",
       " \"swimming is above all about a young woman's face, and by casting an actress whose face projects that woman's doubts and yearnings, it succeeds.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][1,8,11,19]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3844e1-66dd-44f3-8231-7d9861f0005a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f37a718-ea95-4948-8fb0-739c151e6375",
   "metadata": {},
   "source": [
    "Let's have a look at the labels: This is a binary classification task.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47d832f1-11f2-42d2-960f-a7df2394b4f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': 'goes to absurd lengths', 'labels': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e335bd4a-f6a0-40c4-b71d-d82229cbb2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['negative', 'positive'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'].features['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b48aa57-9454-4cfc-9f6e-1b927c451a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'positive'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label = {\n",
    "    class_id: class_label\n",
    "    for class_id, class_label in enumerate(\n",
    "        dataset['train'].features['labels'].names\n",
    "    )\n",
    "}\n",
    "id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "450dc1e8-3c05-465c-9707-17553d7e0e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = dataset['train'].features['labels'].num_classes \n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c26386a-30c3-4bdd-8f9a-d37867e990ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf797244-cea9-4f42-9885-25b12458cba2",
   "metadata": {},
   "source": [
    "### Load pre-trained (base) model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b35ce0-7b73-49d0-b2c3-0609798a43c6",
   "metadata": {},
   "source": [
    "We use as pre-trained model for our adapter the Gemma 2B (a pre-trained decoder-only transformer) model with a sequence classification head. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3574e86d-fa2f-4aa9-a220-8b2eba0ef35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82e636e8-1189-4171-9529-54dc52e57f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb2bcac9dd64991a421f072689b311a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GemmaForSequenceClassification LOAD REPORT from: google/gemma-2b\n",
      "Key          | Status  | \n",
      "-------------+---------+-\n",
      "score.weight | MISSING | \n",
      "\n",
      "Notes:\n",
      "- MISSING\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_id, \n",
    "    num_labels=num_classes,\n",
    "    id2label=id2label,\n",
    "    )\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model.config.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "tokenizer.padding_side = 'left' # makes sure last token is an actual text token, not a padding token\n",
    "tokenizer.truncation_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debaaa45-8173-4d27-84c8-fc888dfaceeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b462509d-04cd-4e59-a57f-3384a7506cdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'negative', 1: 'positive'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bc9e5-ea5b-4d47-9879-3e324676a427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25e6b572-0413-43c9-b0ac-fae00e010ef6",
   "metadata": {},
   "source": [
    "Since the classification head is newly initialized at random, we *save* the head initial state (weights) to have a record of all the parameters of the adapter's pre-trained base model before fine-tuning begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25d271cc-f2db-4f51-9fb4-79a5fbffe13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving weight initialization for classification head\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0267, -0.0111,  0.0249,  ..., -0.0620, -0.0033,  0.0023],\n",
       "        [-0.0193,  0.0204,  0.0153,  ...,  0.0135,  0.0015,  0.0271]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('saving weight initialization for classification head:')\n",
    "head_init = model.score.weight.data\n",
    "head_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a937875-be35-441f-8326-b7468d36745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "caa6a4fb-10e2-47fb-93d3-a1038d0cca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(head_init, \n",
    "           os.path.join(save_dir,'head_init.pt'))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adb416f8-880e-48c7-989e-7913b16765bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a31f85a1-20be-4d4b-8380-f8acc38bea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "safetensors.torch.save_file(\n",
    "    {'head': head_init.contiguous()}, \n",
    "    os.path.join(save_dir,'head_init.safetensors'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa84c0aa-c969-4aea-820e-a5bde97cf484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking head weights were saved correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "971917a5-e2d4-4803-8567-bfa21e7197e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'head': tensor([[-0.0267, -0.0111,  0.0249,  ..., -0.0620, -0.0033,  0.0023],\n",
       "         [-0.0193,  0.0204,  0.0153,  ...,  0.0135,  0.0015,  0.0271]],\n",
       "        dtype=torch.bfloat16)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "safetensors.torch.load_file(\n",
    "    os.path.join(save_dir, 'head_init.safetensors'), \n",
    "    device='cpu')#['head']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40b716b0-1845-4b58-9ab1-dbb42a4190af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0267, -0.0111,  0.0249,  ..., -0.0620, -0.0033,  0.0023],\n",
       "        [-0.0193,  0.0204,  0.0153,  ...,  0.0135,  0.0015,  0.0271]],\n",
       "       dtype=torch.bfloat16)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\n",
    "    os.path.join(save_dir, 'head_init.pt'), \n",
    "    map_location='cpu', \n",
    "    weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68062c73-1def-413d-8936-0e2f12baceae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab4bfe39-16d5-4c23-be98-7a66ad7891af",
   "metadata": {},
   "source": [
    "### Create SpaRTA adapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1977426-0f1e-4c86-a4a5-b22e8353751a",
   "metadata": {},
   "source": [
    "Instead of full fine-tuning, we wrap the model with SpaRTA to significantly reduce the number of trainable parameters. We choose a sparsity = 99%, so only about 1% of the model parameters will be updated during training. This will also help prevent overfitting on our small training dataset, as we will see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9cc1c40-cc53-4470-9868-5229ef9b367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft_sparta import SpaRTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c62e31b-3ac4-4980-9d6d-1691ec7383c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SpaRTA(model, 0.99).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be654561-7d5e-4e11-9a84-6a8d27ce7224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseModel(sparsity=0.99, frozen_modules=['embed_tokens', 'self_attn.q', 'self_attn.k', 'mlp', 'norm'], dropout_rate=0.0,\n",
       "  GemmaForSequenceClassification(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): GELUActivation()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): GemmaRotaryEmbedding()\n",
       "  )\n",
       "  (score): Linear(in_features=2048, out_features=2, bias=False)\n",
       ")\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "edbd81c2-32c3-4b14-ac85-a950fa1de21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num trainable parameters: 25,067,043 (1.00021%)\n"
     ]
    }
   ],
   "source": [
    "model.num_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94fb678-b3bc-47ca-9688-f13f1225a233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "46e9c10d-f4d7-4418-b8e9-680bbf999829",
   "metadata": {},
   "source": [
    "### Training SpaRTA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cee45fb-97ad-429b-83d9-1ca35e785a82",
   "metadata": {
    "tags": []
   },
   "source": [
    "We use the Hugging Face trainer to fine-tune our SpaRTA adater."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "11dc9aa7-16a8-490f-8486-e846f9fed55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7913654c-4e30-4af9-a8f8-db323e0c0ff7",
   "metadata": {},
   "source": [
    "pre-tokenize the dataset before training for efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7254b6c6-995d-477c-840e-bf8c69419fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(examples):\n",
    "    return tokenizer(examples['sentence'], truncation=True, padding='max_length', max_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6796847b-a349-42ac-9589-9fa485cab92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns('sentence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4a208d-432f-433d-9dd2-9c97d25a193f",
   "metadata": {},
   "source": [
    "define accuracy as a metric to evaluate the performance of our classification model (on the evaluation dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0fa3745-06b9-496d-ad1c-914413ffccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_accuracy(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = logits.argmax(-1)\n",
    "    return {'accuracy': (preds == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4d15c9-ccfa-439f-a757-137f06ce1a44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4efcc489-8977-4b4a-b4b1-d3a21ae80a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_config = TrainingArguments(\n",
    "    output_dir=save_dir,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=40,\n",
    "    gradient_accumulation_steps=1,\n",
    "    weight_decay=0.02,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=100,\n",
    "    logging_first_step=True,\n",
    "    batch_eval_metrics = False, \n",
    "    eval_strategy=\"steps\",\n",
    "    eval_on_start=True,\n",
    "    eval_steps=100,\n",
    "    label_names=[\"labels\"],\n",
    "    per_device_eval_batch_size=40,\n",
    "    gradient_checkpointing=False,\n",
    "    save_strategy=\"no\",\n",
    "    load_best_model_at_end=False,\n",
    "    report_to=\"none\",\n",
    "    push_to_hub=False,\n",
    "    remove_unused_columns=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da00ab6-7395-4fa7-9a5a-207987a41eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://huggingface.co/docs/transformers/v5.1.0/en/main_classes/trainer#transformers.TrainingArguments\n",
    "# sft_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2af347fb-1303-4d42-9b39-4474c6044ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    args=sft_config,\n",
    "    compute_metrics=classification_accuracy,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4610c95-ff35-47fb-a6f9-b0ed0491b4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='44' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:33]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.5605647563934326,\n",
       " 'eval_model_preparation_time': 0.0032,\n",
       " 'eval_accuracy': 0.5091743119266054,\n",
       " 'eval_runtime': 2.111,\n",
       " 'eval_samples_per_second': 413.072,\n",
       " 'eval_steps_per_second': 10.422}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63f5af9e-90f1-4aeb-af9b-217be563afee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1684' max='1684' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1684/1684 05:33, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Model Preparation Time</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.560565</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.509174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.537524</td>\n",
       "      <td>0.184857</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.942661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.208059</td>\n",
       "      <td>0.158157</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.181113</td>\n",
       "      <td>0.142214</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.163779</td>\n",
       "      <td>0.141742</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.959862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.156539</td>\n",
       "      <td>0.138036</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.144659</td>\n",
       "      <td>0.130729</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.138549</td>\n",
       "      <td>0.132415</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.961009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.133481</td>\n",
       "      <td>0.139374</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.955275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.139922</td>\n",
       "      <td>0.138483</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.956422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.133971</td>\n",
       "      <td>0.138381</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.136532</td>\n",
       "      <td>0.129228</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.958716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.139031</td>\n",
       "      <td>0.123151</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.121155</td>\n",
       "      <td>0.123017</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.963303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.132272</td>\n",
       "      <td>0.120694</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.964450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.122428</td>\n",
       "      <td>0.121025</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.967890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.118630</td>\n",
       "      <td>0.121952</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.969037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1684, training_loss=0.16799183752644373, metrics={'train_runtime': 335.2536, 'train_samples_per_second': 200.89, 'train_steps_per_second': 5.023, 'total_flos': 0.0, 'train_loss': 0.16799183752644373, 'epoch': 1.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a716acac-44ac-4541-8f78-f10bfa8bea7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22' max='22' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22/22 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.1213647648692131,\n",
       " 'eval_model_preparation_time': 0.0032,\n",
       " 'eval_accuracy': 0.9701834862385321,\n",
       " 'eval_runtime': 1.2715,\n",
       " 'eval_samples_per_second': 685.79,\n",
       " 'eval_steps_per_second': 17.302,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6cf81e-450e-4ab3-a0d4-021a5919949d",
   "metadata": {},
   "source": [
    "Note, how the *accuracy* of the model (on the evaluation split) goes from around 50.9% to 97.0%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256cc7f4-df1a-4128-94c8-c45032addb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b55284f-f31a-427d-b0c1-fa4fd957ff7f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Inference (classify) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860af359-ce3b-4d93-be5d-bc624dccae9c",
   "metadata": {},
   "source": [
    "Let's test the SpaRTA adapted model on a sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "47db7d36-a7a4-4475-82cf-dce9f23a52bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class id prediction: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = \"It was a great movie\" \n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\", truncation=True, max_length=128).to(\"cuda\")\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "pred_class_id = logits.argmax().item()\n",
    "print('class id prediction:', pred_class_id)\n",
    "dataset['train'].features['labels'].int2str(pred_class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab13570f-8895-4f68-8481-9614b3e199c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d49851-f9a7-4405-b759-b9ddb5422197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5501a399-b837-4520-a653-51da22481756",
   "metadata": {},
   "source": [
    "### Save the SpaRTA adapter to disk for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f0426890-dd01-427e-8a59-15c7529fd3cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['head_init.safetensors', 'head_init.pt']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcae167-3ce5-45a3-a5c1-6e7615a0f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_dir, merged=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34d50b49-15d8-4a73-89cf-0c441ddb7198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['head_init.safetensors',\n",
       " 'config.json',\n",
       " 'sparse_deltas.safetensors',\n",
       " 'head_init.pt']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaef4c1-694e-4d4f-a104-f892b981206f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c5f396d-3a20-481e-a0b1-ef5a03da2cd1",
   "metadata": {},
   "source": [
    "### Reload the SpaRTA adapter "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024cea54-2582-4199-b59c-da5e7d18a6c2",
   "metadata": {},
   "source": [
    "Use can use the `SpaRTAforSequenceClassification` class to load the saved adapter and do inference (classification) using the `classify` and `decide_class` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bdb5475f-5411-48aa-8c44-c3648fc8be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c59cdb51-4495-43f7-a76e-f4dfb1fc000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft_sparta import SpaRTAforSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44621beb-7826-4954-84f7-844676c2058e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0a10c6c26f34b3db42ab54f4069faed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = SpaRTAforSequenceClassification(\n",
    "   adapter = save_dir,\n",
    "   device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70eb6ff4-9d2c-48e6-ae6b-b89f46ce6377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(SpaRTA)ModelForSeqClassification(\n",
      "\tadapter = '/u/jriosal/sparta_examples/output/classification_model/'\n",
      "\tmodel = 'google/gemma-2b'\n",
      "\tid2label = {0: 'negative', 1: 'positive'}\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30eba7d-2a30-481a-a016-4d68ee565687",
   "metadata": {},
   "source": [
    "Let's test the adapted model on a couple of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eec31f98-ddd1-4de3-b285-f2bec3ddcc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"The movie was great\", \n",
    "             \"I hate that movie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "003ce520-3798-480f-a33c-92c59cbcc8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0032, 0.9968],\n",
       "        [0.9986, 0.0014]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classify(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5f60a827-ce16-4445-98e4-cdf664e65e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positive', 'negative']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decide_class(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c62f3f-2e2c-472d-a003-3fe401bc37cc",
   "metadata": {},
   "source": [
    "In this case, the adapted model predicts the correct sentiment for both of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0b029e-4f44-4aac-96ff-1b644db28869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "480be380-dfd6-4255-8a6e-8b6312d9c8ad",
   "metadata": {},
   "source": [
    "### Evaluation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afced6a1-503a-4af7-860e-8adf994f302b",
   "metadata": {},
   "source": [
    "We can also evaluate the performance of the adapter in a labeled dataset with the `evaluate` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d9f584a5-89c9-4133-9205-4b590943d51e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.1213341415475268,\n",
       " 'accuracy': 0.9690366972477065,\n",
       " 'confusion matrix': tensor([[416,  12],\n",
       "         [ 15, 429]], dtype=torch.int32),\n",
       " 'balanced accuracy': 0.9690893888473511,\n",
       " 'MCC': 0.9380825757980347,\n",
       " 'F1-score': 0.9694915413856506}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_sentences = dataset['validation']['sentence']\n",
    "eval_labels = dataset['validation']['labels']\n",
    "model.evaluate(eval_sentences, eval_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9115c3-4d5c-4d43-a667-c1baa2527f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
